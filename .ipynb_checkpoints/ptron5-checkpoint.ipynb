{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data - also - Input layer\n",
    "training_X= np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "training_Y = np.array([[0],[1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model a class with input layer 4x3\n",
    "# Hidden layer 3 x 4\n",
    "# output layer 4 x 1\n",
    "\n",
    "class Perceptron(object):\n",
    "    def __init__(self):\n",
    "        self.ilw = np.random.rand(3,4) #setup random weights for input layer\n",
    "        self.hlw = np.random.rand(4,4) # setup random weights for hidden layer\n",
    "        self.olw = np.random.rand(4,1) # setup random weights for output layer\n",
    "        \n",
    "    def sigmoid(self, dot_product):\n",
    "        return 1 / (1 + np.exp(-dot_product))\n",
    "    \n",
    "    def step(self, dot_product):\n",
    "        step_transform = []\n",
    "        for item in dot_product:\n",
    "            if item >= .5:\n",
    "                step_transform.append(1)\n",
    "            elif item < .5:\n",
    "                step_transform.append(0)\n",
    "        return(np.array(step_transform, ndmin=2)) # need ndmin 2 to avoid (4,) we need (4,1)\n",
    "    \n",
    "    def sigmoid_derivative(self, dot_product):\n",
    "        return dot_product * (1 - dot_product)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptron = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step one get the dot products for the layers\n",
    "ilr = np.dot(training_X, ptron.ilw)\n",
    "hlr = np.dot(ilr, ptron.hlw)\n",
    "olr = np.dot(hlr, ptron.olw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilr \n",
      "[[ 0.73965863  0.88358669  0.60861958  0.01903352]\n",
      " [ 1.78143152  1.73027882  2.09558792  1.61810856]\n",
      " [ 1.52581868  0.96322956  1.34975098  0.74040638]\n",
      " [ 0.99527146  1.65063595  1.35445652  0.89673569]] \n",
      " hlr \n",
      " [[ 1.39285     1.28318946  0.92102226  0.51593638]\n",
      " [ 3.58766873  3.61237949  2.15562882  1.99525044]\n",
      " [ 2.41541104  2.60815378  1.3621007   1.18499108]\n",
      " [ 2.56510768  2.28741517  1.71455038  1.32619574]]\n",
      " olr \n",
      " [[ 1.21522192]\n",
      " [ 3.0552578 ]\n",
      " [ 2.00846982]\n",
      " [ 2.2620099 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ilr \\n{} \\n hlr \\n {}\\n olr \\n {}\".format(ilr, hlr, olr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 - run each layer through it's activation function\n",
    "ilr2 = ptron.sigmoid(ilr)\n",
    "hlr2 = ptron.sigmoid(hlr)\n",
    "olr2 = ptron.sigmoid(olr).T # this is a 1x4 matrix and we need 4x1 to subtract so transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilr2 \n",
      "[[ 0.6769212   0.70756492  0.64762584  0.50475824]\n",
      " [ 0.85587354  0.84944808  0.89047361  0.83453411]\n",
      " [ 0.82139371  0.72376795  0.79408891  0.67708471]\n",
      " [ 0.73012788  0.83897698  0.79485726  0.71027822]] \n",
      " hlr2 \n",
      " [[ 0.80104684  0.7829922   0.71525035  0.62619707]\n",
      " [ 0.97308188  0.97372164  0.8961936   0.8802975 ]\n",
      " [ 0.91799495  0.9313845   0.7961009   0.76584403]\n",
      " [ 0.92858193  0.90782939  0.84742556  0.79021067]]\n",
      " olr2 \n",
      " [[ 0.7712216   0.95500898  0.88168349  0.90568146]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ilr2 \\n{} \\n hlr2 \\n {}\\n olr2 \\n {}\".format(ilr2, hlr2, olr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 3 - calculate the error\n",
    "error = training_Y - olr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error \n",
      " [[-0.7712216  -0.95500898 -0.88168349 -0.90568146]\n",
      " [ 0.2287784   0.04499102  0.11831651  0.09431854]\n",
      " [ 0.2287784   0.04499102  0.11831651  0.09431854]\n",
      " [-0.7712216  -0.95500898 -0.88168349 -0.90568146]]\n"
     ]
    }
   ],
   "source": [
    "print(\"error \\n {}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 get the deltas - how much do we need to learn\n",
    "# we do dot products from right to left through the network\n",
    "# stepping backwards through each calculation to determine a better set of weights\n",
    "# until we find the set that gets the results we are looking for\n",
    "# like the way the human nervous system sends impulses to the brain that then processes and \n",
    "# sends back a response\n",
    "\n",
    "# change in the output layer is derrived from the error\n",
    "\n",
    "do = ptron.sigmoid_derivative(olr2) * error # delta=output layer-error times derivitive of output layer\n",
    "\n",
    "dh = do.dot(olr2.T) * ptron.sigmoid_derivative(hlr2) \n",
    "\n",
    "# dH = dZ.dot(Wz.T) * sigmoid_(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do \n",
      " [[-0.13607345 -0.04103371 -0.09197521 -0.07736562]\n",
      " [ 0.0403654   0.00193312  0.01234251  0.00805693]\n",
      " [ 0.0403654   0.00193312  0.01234251  0.00805693]\n",
      " [-0.13607345 -0.04103371 -0.09197521 -0.07736562]]\n",
      " dh\n",
      " [[-0.04706092 -0.05017466 -0.06014131 -0.06912026]\n",
      " [ 0.00133996  0.00130897  0.00475908  0.0053905 ]\n",
      " [ 0.00385104  0.00326925  0.00830386  0.00917365]\n",
      " [-0.01958303 -0.02470861 -0.03817992 -0.04895284]]\n"
     ]
    }
   ],
   "source": [
    "print(\"do \\n {}\\n dh\\n {}\".format(do,dh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 Update the weights for the next iteration or epoch\n",
    "#  Wz +=  H.T.dot(dZ)                          # update output layer weights\n",
    "ptron.ilw = np.dot(ilr2,olr2.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.2259383 ],\n",
       "       [ 3.01223666],\n",
       "       [ 2.63803963],\n",
       "       [ 2.70841929]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.ilw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 4), (4, 1))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olr2.shape, training_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.51594211,  0.63838857,  0.55177584,  0.6184278 ],\n",
       "        [ 0.7923126 ,  0.78364446,  0.62807226,  0.75307008],\n",
       "        [ 0.74173467,  0.70912423,  0.56106647,  0.71628079],\n",
       "        [ 0.58606164,  0.72397688,  0.61923741,  0.66191659]]),\n",
       " array([[ 0.62349393,  0.55756877,  0.67306074,  0.64910651],\n",
       "        [ 0.82083168,  0.66163391,  0.89604174,  0.93156158],\n",
       "        [ 0.72930755,  0.6033624 ,  0.83683684,  0.87373495],\n",
       "        [ 0.73793922,  0.61831204,  0.77576938,  0.78442603]]),\n",
       " array([1, 1, 1, 1]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilr2, hlr2, olr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.99121407,  0.32275752,  0.03764298,  0.4432068 ],\n",
       "        [ 0.28391783,  0.39589792,  0.27846427,  0.18896654],\n",
       "        [ 0.06379005,  0.56837692,  0.20784839,  0.48288038]]),\n",
       " array([[ 0.27965337,  0.09262718,  0.40034355,  0.99002406],\n",
       "        [ 0.53417628,  0.06843972,  0.3129677 ,  0.45601461],\n",
       "        [ 0.85431021,  0.63266396,  0.39868224,  0.50902435],\n",
       "        [ 0.01115239,  0.11388817,  0.90244741,  0.38720216]]),\n",
       " array([[ 0.12651864],\n",
       "        [ 0.50352375],\n",
       "        [ 0.26456513],\n",
       "        [ 0.6554159 ]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.ilw, ptron.hlw, ptron.olw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
