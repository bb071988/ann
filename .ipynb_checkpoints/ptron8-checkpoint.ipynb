{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data - also - Input layer\n",
    "training_X= np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "# training_Y = np.array([[0],[1], [1], [0]])\n",
    "training_Y = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model a class with input layer 4x3\n",
    "# Hidden layer 3 x 4\n",
    "# output layer 4 x 1\n",
    "\n",
    "class Perceptron(object):\n",
    "    def __init__(self):\n",
    "        self.ilw = np.random.rand(3,4) #setup random weights for input layer\n",
    "        self.hlw = np.random.rand(4,4) # setup random weights for hidden layer\n",
    "        self.olw = np.random.rand(4,1) # setup random weights for output layer\n",
    "        \n",
    "    def sigmoid(self, dot_product):\n",
    "        return 1 / (1 + np.exp(-dot_product))\n",
    "    \n",
    "    def step(self, dot_product):\n",
    "        step_transform = []\n",
    "        for item in dot_product:\n",
    "            if item >= .5:\n",
    "                step_transform.append(1)\n",
    "            elif item < .5:\n",
    "                step_transform.append(0)\n",
    "        return(np.array(step_transform, ndmin=2)) # need ndmin 2 to avoid (4,) we need (4,1)\n",
    "    \n",
    "    def sigmoid_derivative(self, dot_product):\n",
    "        return dot_product * (1 - dot_product)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptron = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new order - process the input layer first\n",
    "ilr = np.dot(training_X, ptron.ilw)\n",
    "ilr2 = ptron.sigmoid(ilr)\n",
    "\n",
    "# process the hidden layer\n",
    "hlr = np.dot(ilr2, ptron.hlw) # was taking ilr here not ilr2 in ptron5\n",
    "hlr2 = ptron.sigmoid(hlr)\n",
    "\n",
    "# process the output layer\n",
    "olr = np.dot(hlr2, ptron.olw)\n",
    "olr2 = ptron.sigmoid(olr).T # this is a 1x4 matrix and we need 4x1 to subtract so transpose\n",
    "\n",
    "# step 3 - calculate the error\n",
    "error = training_Y - olr2\n",
    "\n",
    "# step 4 get the deltas - how much do we need to learn\n",
    "# we do dot products from right to left through the network\n",
    "# stepping backwards through each calculation to determine a better set of weights\n",
    "# until we find the set that gets the results we are looking for\n",
    "# like the way the human nervous system sends impulses to the brain that then processes and \n",
    "# sends back a response\n",
    "\n",
    "# change in the output layer is derrived from the error\n",
    "\n",
    "do = ptron.sigmoid_derivative(olr2) * error # delta=output layer-error times derivitive of output layer\n",
    "\n",
    "dh = do.dot(olr2.T) * ptron.sigmoid_derivative(hlr2) \n",
    "\n",
    "# dH = dZ.dot(Wz.T) * sigmoid_(H)\n",
    "\n",
    "# step 5 Update the weights for the next iteration or epoch\n",
    "#  Wz +=  H.T.dot(dZ)                          # update output layer weights\n",
    "ptron.ilw = np.dot(ilr2,olr2.T)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.52132565  0.70087901  0.53045776  0.60460078]\n",
      " [ 0.61255444  0.78494022  0.67726455  0.77096948]\n",
      " [ 0.59926747  0.73098664  0.66435821  0.70592531]\n",
      " [ 0.53519246  0.75887919  0.54498654  0.68195924]]\n"
     ]
    }
   ],
   "source": [
    "print(ilr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70388623  0.75921751  0.86395549  0.85783237]\n",
      " [ 0.74630431  0.79705874  0.90455502  0.89831786]\n",
      " [ 0.73321839  0.78186318  0.89365742  0.88772717]\n",
      " [ 0.72014748  0.77758385  0.8792089   0.87245511]]\n"
     ]
    }
   ],
   "source": [
    "print(hlr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7450305   0.75598169  0.75277259  0.74923118]]\n"
     ]
    }
   ],
   "source": [
    "print(olr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.77421507 -0.78959457  0.21513393  0.21824822]]\n"
     ]
    }
   ],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.95981503]\n",
      " [ 2.60287745]\n",
      " [ 2.36278041]\n",
      " [ 2.26867005]]\n"
     ]
    }
   ],
   "source": [
    "print(ptron.ilw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step one get the dot products for the layers\n",
    "ilr = np.dot(training_X, ptron.ilw)\n",
    "hlr = np.dot(ilr, ptron.hlw)\n",
    "olr = np.dot(hlr, ptron.olw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilr \n",
      "[[ 0.89181947  0.78186898  0.17408649  0.38088003]\n",
      " [ 2.53603283  1.27024619  0.87640446  0.61122804]\n",
      " [ 1.61830019  0.98871383  0.28971365  0.39048448]\n",
      " [ 1.8095521   1.06340135  0.76077731  0.60162359]] \n",
      " hlr \n",
      " [[ 0.93542435  1.13359935  1.453148    0.72588914]\n",
      " [ 2.47247652  2.79260981  3.83026404  1.67389096]\n",
      " [ 1.51236395  1.65800952  2.25685284  1.1086152 ]\n",
      " [ 1.89553691  2.26819965  3.0265592   1.2911649 ]]\n",
      " olr \n",
      " [[ 2.5398337 ]\n",
      " [ 6.44427407]\n",
      " [ 3.96019081]\n",
      " [ 5.02391696]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ilr \\n{} \\n hlr \\n {}\\n olr \\n {}\".format(ilr, hlr, olr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 2 - run each layer through it's activation function\n",
    "ilr2 = ptron.sigmoid(ilr)\n",
    "hlr2 = ptron.sigmoid(hlr)\n",
    "olr2 = ptron.sigmoid(olr).T # this is a 1x4 matrix and we need 4x1 to subtract so transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilr2 \n",
      "[[ 0.7092655   0.68608278  0.54341204  0.59408534]\n",
      " [ 0.92662957  0.78078489  0.70607658  0.64822088]\n",
      " [ 0.83456057  0.7288338   0.57192603  0.59639932]\n",
      " [ 0.85930773  0.74334001  0.68152247  0.64602767]] \n",
      " hlr2 \n",
      " [[ 0.71817447  0.75650253  0.81048244  0.67390252]\n",
      " [ 0.92218966  0.94227516  0.97875717  0.8420939 ]\n",
      " [ 0.81941128  0.83997062  0.90524001  0.75187085]\n",
      " [ 0.86938556  0.90620888  0.95375966  0.78434429]]\n",
      " olr2 \n",
      " [[ 0.92688756  0.99841292  0.98129699  0.99346429]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ilr2 \\n{} \\n hlr2 \\n {}\\n olr2 \\n {}\".format(ilr2, hlr2, olr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 3 - calculate the error\n",
    "error = training_Y - olr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error \n",
      " [[-0.92688756  0.00158708  0.01870301 -0.99346429]]\n"
     ]
    }
   ],
   "source": [
    "print(\"error \\n {}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 4 get the deltas - how much do we need to learn\n",
    "# we do dot products from right to left through the network\n",
    "# stepping backwards through each calculation to determine a better set of weights\n",
    "# until we find the set that gets the results we are looking for\n",
    "# like the way the human nervous system sends impulses to the brain that then processes and \n",
    "# sends back a response\n",
    "\n",
    "# change in the output layer is derrived from the error\n",
    "\n",
    "do = ptron.sigmoid_derivative(olr2) * error # delta=output layer-error times derivitive of output layer\n",
    "\n",
    "dh = do.dot(olr2.T) * ptron.sigmoid_derivative(hlr2) \n",
    "\n",
    "# dH = dZ.dot(Wz.T) * sigmoid_(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do \n",
      " [[ -6.28124013e-02   2.51481037e-06   3.43260138e-04  -6.45055922e-03]]\n",
      " dh\n",
      " [[-0.0130121  -0.01184246 -0.00987485 -0.01412803]\n",
      " [-0.00461312 -0.00349686 -0.00133667 -0.00854863]\n",
      " [-0.00951327 -0.00864174 -0.00551475 -0.01199384]\n",
      " [-0.0073003  -0.00546421 -0.00283529 -0.01087439]]\n"
     ]
    }
   ],
   "source": [
    "print(\"do \\n {}\\n dh\\n {}\".format(do,dh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 5 Update the weights for the next iteration or epoch\n",
    "#  Wz +=  H.T.dot(dZ)                          # update output layer weights\n",
    "ptron.ilw = np.dot(ilr2,olr2.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.46585446],\n",
       "       [ 2.97528227],\n",
       "       [ 2.65495162],\n",
       "       [ 2.84922329]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.ilw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 4), (4,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olr2.shape, training_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.7092655 ,  0.68608278,  0.54341204,  0.59408534],\n",
       "        [ 0.92662957,  0.78078489,  0.70607658,  0.64822088],\n",
       "        [ 0.83456057,  0.7288338 ,  0.57192603,  0.59639932],\n",
       "        [ 0.85930773,  0.74334001,  0.68152247,  0.64602767]]),\n",
       " array([[ 0.71817447,  0.75650253,  0.81048244,  0.67390252],\n",
       "        [ 0.92218966,  0.94227516,  0.97875717,  0.8420939 ],\n",
       "        [ 0.81941128,  0.83997062,  0.90524001,  0.75187085],\n",
       "        [ 0.86938556,  0.90620888,  0.95375966,  0.78434429]]),\n",
       " array([[ 0.92688756,  0.99841292,  0.98129699,  0.99346429]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilr2, hlr2, olr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.99121407,  0.32275752,  0.03764298,  0.4432068 ],\n",
       "        [ 0.28391783,  0.39589792,  0.27846427,  0.18896654],\n",
       "        [ 0.06379005,  0.56837692,  0.20784839,  0.48288038]]),\n",
       " array([[ 0.27965337,  0.09262718,  0.40034355,  0.99002406],\n",
       "        [ 0.53417628,  0.06843972,  0.3129677 ,  0.45601461],\n",
       "        [ 0.85431021,  0.63266396,  0.39868224,  0.50902435],\n",
       "        [ 0.01115239,  0.11388817,  0.90244741,  0.38720216]]),\n",
       " array([[ 0.12651864],\n",
       "        [ 0.50352375],\n",
       "        [ 0.26456513],\n",
       "        [ 0.6554159 ]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.ilw, ptron.hlw, ptron.olw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
