{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data - also - Input layer\n",
    "X= np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "# training_Y = np.array([[0],[1], [1], [0]])\n",
    "y = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single perceptron\n",
    "\n",
    "class Perceptron(object):\n",
    "    def __init__(self, X):\n",
    "        \n",
    "        # Model a single neuron with variable (3 in xor case) input connections and 1 output\n",
    "        # we have 4 examples with three inputs each\n",
    "        \n",
    "        self.weight = np.random.rand(X.shape[1],1) # initialize with a weight n x 1\n",
    "#         print(self.weight)\n",
    "        self.error = 0\n",
    "        self.output = 0\n",
    "#         self.weighted_sum = 0\n",
    "        self.shape = (0,0)\n",
    "        \n",
    "    def stim(self): # stimulate the perceptron - run the values through the sensor\n",
    "#         return(X[val] * self.weight[val])\n",
    "        return(self.sigmoid(np.dot(X,self.weight)))\n",
    "        \n",
    "    def sigmoid(self, weighted_sum):\n",
    "        return 1 / (1 + np.exp(-weighted_sum))\n",
    "    \n",
    "    def sigmoid_(self, weighted_sum):\n",
    "        return(weighted_sum * (1 - weighted_sum))\n",
    "    \n",
    "    def get_output(self): # calculate how much stimulation the perceptron perceives\n",
    "        return(self.stim())\n",
    "        \n",
    "        \n",
    "#         for val, input in enumerate(X): # run each input through the node\n",
    "#             response  = ptron.stim(val)\n",
    "#             response += response\n",
    "#         self.weighted_sum = response.sum()\n",
    "#         self.weighted_sum = self.sigmoid(self.stim)\n",
    "            \n",
    "\n",
    "#         self.weighted_sum = self.stim()\n",
    "#         print(\"self.weighted_sum in get_output {}\".format(self.weighted_sum))\n",
    "#         self.output = ptron.sigmoid()\n",
    "#         print(\"self.output in get_output {}\".format(self.output))\n",
    "#         self.shape = self.output.shape\n",
    "#         print(\"self.shape in get_output {}\".format(self.shape))\n",
    "#         return(self.output) # this returns a single value which I think is correct\n",
    "    \n",
    "    def get_error(self, y): \n",
    "        self.error = (y - self.get_output)\n",
    "        return(self.error)\n",
    "\n",
    "    def get_delta(self, ):\n",
    "         adjustment = dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
    "        delta = dot(X.T, error * self.sigmoid_()  ***************************** stopping here too many self. values\n",
    "        pass\n",
    "        \n",
    "        # calculate gradient and adjustment and make adjustment *******************\n",
    "        \n",
    "    \n",
    "#     def learn(self, X , weight):\n",
    "        \n",
    "    \n",
    "#     def step(self, dot_product):\n",
    "#         step_transform = []\n",
    "#         for item in dot_product:\n",
    "#             if item >= .5:\n",
    "#                 step_transform.append(1)\n",
    "#             elif item < .5:\n",
    "#                 step_transform.append(0)\n",
    "#         return(np.array(step_transform, ndmin=2)) # need ndmin 2 to avoid (4,) we need (4,1)\n",
    "    \n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50368829]\n",
      " [ 0.55797303]\n",
      " [ 0.52797954]\n",
      " [ 0.53386257]]\n",
      "[0 0 1 1]\n",
      "[[-0.50368829 -0.50368829  0.49631171  0.49631171]\n",
      " [-0.55797303 -0.55797303  0.44202697  0.44202697]\n",
      " [-0.52797954 -0.52797954  0.47202046  0.47202046]\n",
      " [-0.53386257 -0.53386257  0.46613743  0.46613743]]\n"
     ]
    }
   ],
   "source": [
    "# layer 1 one node layer 2 one node\n",
    "l1 = Perceptron(X)\n",
    "l1_out = l1.get_output()\n",
    "print(l1_out)\n",
    "print(y)\n",
    "l1_error = l1.get_error(y) # don't think we need to transpose - numpy 1d transpose gives unchagned arrray\n",
    "print(l1_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58842829],\n",
       "       [ 0.74584251],\n",
       "       [ 0.60748363],\n",
       "       [ 0.73052448]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-cd8b97f78e21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ml2_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-58cd48d1ad2e>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# initialize with a weight 3x4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#         print(self.weight)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "l2 = Perceptron(l1)\n",
    "l2_out = l2.get_output()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.97898034, -0.97898034,  0.02101966,  0.02101966])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.get_error(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.50169877],\n",
       "       [ 0.50169877,  0.50169877,  0.50169877],\n",
       "       [ 0.50169877,  0.        ,  0.50169877],\n",
       "       [ 0.        ,  0.50169877,  0.50169877]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0135901738290931"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# new order - process the input layer first\n",
    "ilr = np.dot(training_X, ptron.ilw)\n",
    "ilr2 = ptron.sigmoid(ilr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64696247,  0.61468396,  0.71890328,  0.54121975],\n",
       "       [ 0.79341786,  0.81728366,  0.90460499,  0.68153225],\n",
       "       [ 0.7706354 ,  0.64697149,  0.86059557,  0.57698133],\n",
       "       [ 0.67687849,  0.79565278,  0.79709804,  0.64923604]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4) (4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(ilr.shape,ilr2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process the hidden layer\n",
    "hlr = np.dot(ilr2, ptron.hlw) # was taking ilr here not ilr2 in ptron5\n",
    "hlr2 = ptron.sigmoid(hlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75103429],\n",
       "       [ 0.80568839],\n",
       "       [ 0.7725091 ],\n",
       "       [ 0.79078367]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1), (4, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlr.shape,hlr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process the output layer\n",
    "olr = np.dot(hlr2, ptron.olw)\n",
    "olr2 = ptron.sigmoid(olr) # this is a 1x4 matrix and we need 4x1 to subtract so transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.55835966,  0.59473289,  0.6607392 ,  0.64528449],\n",
       "       [ 0.56256363,  0.60144241,  0.67152688,  0.65518736],\n",
       "       [ 0.56001253,  0.59737358,  0.66499862,  0.64919098],\n",
       "       [ 0.56141803,  0.59961631,  0.66860227,  0.65249965]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 4), (4, 4))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olr.shape, olr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 3 - calculate the error\n",
    "error = training_Y - olr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55835966, -0.59473289,  0.3392608 ,  0.35471551],\n",
       "       [-0.56256363, -0.60144241,  0.32847312,  0.34481264],\n",
       "       [-0.56001253, -0.59737358,  0.33500138,  0.35080902],\n",
       "       [-0.56141803, -0.59961631,  0.33139773,  0.34750035]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # step 4 get the deltas - how much do we need to learn\n",
    "    # we do dot products from right to left through the network\n",
    "    # stepping backwards through each calculation to determine a better set of weights\n",
    "    # until we find the set that gets the results we are looking for\n",
    "    # like the way the human nervous system sends impulses to the brain that then processes and \n",
    "    # sends back a response\n",
    "\n",
    "    # change in the output layer is derrived from the error\n",
    "\n",
    "    do = ptron.sigmoid_derivative(olr2) * error # delta=output layer-error times derivitive of output layer\n",
    "\n",
    "    dh = do.dot(olr2) * ptron.sigmoid_derivative(hlr2) # olr2 was T ****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.13768823 -0.1433459   0.07604969  0.08119169]\n",
      " [-0.13843892 -0.14417142  0.07245412  0.077899  ]\n",
      " [-0.13798624 -0.14367933  0.07463009  0.07989397]\n",
      " [-0.13823674 -0.14395384  0.07342888  0.07879357]]\n"
     ]
    }
   ],
   "source": [
    "print(do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24659415,  0.24102568,  0.22416291,  0.22889242],\n",
       "       [ 0.24608579,  0.23970944,  0.22057853,  0.22591688],\n",
       "       [ 0.2463985 ,  0.24051839,  0.22277546,  0.22774205],\n",
       "       [ 0.24622783,  0.24007659,  0.22157327,  0.22674386]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.sigmoid_derivative(olr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01296709 -0.01383442 -0.01540332 -0.01503673]\n",
      " [-0.01159994 -0.01237616 -0.0137802  -0.01345213]\n",
      " [-0.01251735 -0.01335475 -0.01486948 -0.01451555]\n",
      " [-0.01204634 -0.01285234 -0.01431026 -0.0139696 ]]\n"
     ]
    }
   ],
   "source": [
    "print(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02411729, -0.02573091, -0.02864968, -0.02796768],\n",
       "       [-0.02364628, -0.02522849, -0.02809046, -0.02742174],\n",
       "       [-0.04913072, -0.05241766, -0.05836326, -0.05697402]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(training_X.T , dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,3) and (4,4) not aligned: 3 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-304450b8c11c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#  Wz +=  H.T.dot(dZ)                          # update output layer weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#     ptron.ilw += np.dot(ilr2,olr2.T)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0molw\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_X\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhlw\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#     ptron.olw += hlr2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,3) and (4,4) not aligned: 3 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "# step 5 Update the weights for the next iteration or epoch\n",
    "# do I need to update input layer weights?  seems like example does not do that.\n",
    "#  Wz +=  H.T.dot(dZ)                          # update output layer weights\n",
    "#     ptron.ilw += np.dot(ilr2,olr2.T)\n",
    "ptron.olw += np.dot(training_X , dh)\n",
    "ptron.hlw += np.dot\n",
    "#     ptron.olw += hlr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1):\n",
    "\n",
    "    # step 3 - calculate the error\n",
    "    error = training_Y - olr2\n",
    "\n",
    "\n",
    "    # dH = dZ.dot(Wz.T) * sigmoid_(H)\n",
    "\n",
    "    # step 5 Update the weights for the next iteration or epoch\n",
    "    # do I need to update input layer weights?  seems like example does not do that.\n",
    "    #  Wz +=  H.T.dot(dZ)                          # update output layer weights\n",
    "#     ptron.ilw += np.dot(ilr2,olr2.T)\n",
    "    ptron.olw += training_X.T.dot(dh)\n",
    "#     ptron.olw += hlr2\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1), (4, 3), (4, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.olw.shape, training_X.shape, dh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 1, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [1, 1, 1, 1]]), (3, 4))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_X.T, training_X.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01479971, -0.01410536, -0.02175524, -0.02430029],\n",
       "       [-0.00892129, -0.00770688, -0.01602558, -0.02016907],\n",
       "       [-0.01200648, -0.01110821, -0.01879017, -0.02246682],\n",
       "       [-0.01037263, -0.0092141 , -0.01790436, -0.02146303]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ilr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigmoid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6dff13b4d207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# hidden layer results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output layer, no activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;31m# how much we missed (error)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mE\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mL\u001b[0m \u001b[1;31m# delta Z\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mWz\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# update output layer weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sigmoid' is not defined"
     ]
    }
   ],
   "source": [
    "H = sigmoid(np.dot(X, Wh)) # hidden layer results\n",
    "Z = np.dot(H,Wz) # output layer, no activation\n",
    "E = Y - Z # how much we missed (error)\n",
    "dZ = E * L # delta Z\n",
    "Wz += H.T.dot(dZ) # update output layer weights\n",
    "dH = dZ.dot(Wz.T) * sigmoid_(H) # delta H\n",
    "Wh += X.T.dot(dH) # update hidden layer weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(hlr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(olr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ptron.ilw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step one get the dot products for the layers\n",
    "ilr = np.dot(training_X, ptron.ilw)\n",
    "hlr = np.dot(ilr, ptron.hlw)\n",
    "olr = np.dot(hlr, ptron.olw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"ilr \\n{} \\n hlr \\n {}\\n olr \\n {}\".format(ilr, hlr, olr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 2 - run each layer through it's activation function\n",
    "ilr2 = ptron.sigmoid(ilr)\n",
    "hlr2 = ptron.sigmoid(hlr)\n",
    "olr2 = ptron.sigmoid(olr).T # this is a 1x4 matrix and we need 4x1 to subtract so transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"ilr2 \\n{} \\n hlr2 \\n {}\\n olr2 \\n {}\".format(ilr2, hlr2, olr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 3 - calculate the error\n",
    "error = training_Y - olr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"error \\n {}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 4 get the deltas - how much do we need to learn\n",
    "# we do dot products from right to left through the network\n",
    "# stepping backwards through each calculation to determine a better set of weights\n",
    "# until we find the set that gets the results we are looking for\n",
    "# like the way the human nervous system sends impulses to the brain that then processes and \n",
    "# sends back a response\n",
    "\n",
    "# change in the output layer is derrived from the error\n",
    "\n",
    "do = ptron.sigmoid_derivative(olr2) * error # delta=output layer-error times derivitive of output layer\n",
    "\n",
    "dh = do.dot(olr2.T) * ptron.sigmoid_derivative(hlr2) \n",
    "\n",
    "# dH = dZ.dot(Wz.T) * sigmoid_(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"do \\n {}\\n dh\\n {}\".format(do,dh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 5 Update the weights for the next iteration or epoch\n",
    "#  Wz +=  H.T.dot(dZ)                          # update output layer weights\n",
    "ptron.ilw = np.dot(ilr2,olr2.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptron.ilw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "olr2.shape, training_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ilr2, hlr2, olr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptron.ilw, ptron.hlw, ptron.olw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
