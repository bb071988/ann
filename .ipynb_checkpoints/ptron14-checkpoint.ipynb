{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data - also - Input layer\n",
    "X= np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "# training_Y = np.array([[0],[1], [1], [0]])\n",
    "# y = np.array([0, 0, 1, 1]) # this is a one dimensional array and we want a 2 dim array fixing below\n",
    "y = np.array([[0],[0],[1],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a single perceptron for hidden layer\n",
    "\n",
    "class pHidden(object):\n",
    "    def __init__(self, weight_shape):\n",
    "        \n",
    "     # model a single neuron with 3 inputs and 1 output\n",
    "        self.weight = np.random.rand(weight_shape[0], weight_shape[1])\n",
    "        self.error = 0\n",
    "        self.output = 0\n",
    "        self.shape = (0,0)\n",
    "        \n",
    "    def stim(self, X): # stimulate the perceptron - run the values through the sensor\n",
    "        self.output = self.sigmoid(np.dot(X,self.weight))\n",
    "        return(self.output)\n",
    "        \n",
    "    def sigmoid(self, weighted_sum):\n",
    "        return 1 / (1 + np.exp(-weighted_sum))\n",
    "    \n",
    "    def sigmoid_(self, weighted_sum):\n",
    "        return(weighted_sum * (1 - weighted_sum))\n",
    "    \n",
    "##### we get the error at the end of the chain in the output layer\n",
    "    #     def get_error(self, y): \n",
    "#         self.error = (y - self.output)\n",
    "#         return(self.error)\n",
    "\n",
    "    def get_adjustment(self, error_output):  #### updated to take error from output layer\n",
    "        delta = np.dot(X.T, error_output * self.sigmoid_(self.output))  \n",
    "        return(delta)\n",
    "               \n",
    "    def update_weight(self, delta):\n",
    "        self.weight += delta\n",
    "        return(self.weight)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a single perceptron for output layer\n",
    "# output layer doesn't get an activation function\n",
    "\n",
    "class pOutput(object):\n",
    "    def __init__(self, weight_shape):\n",
    "        \n",
    "     # model a single neuron with 3 inputs and 1 output\n",
    "        self.weight = np.random.rand(weight_shape[0], weight_shape[1])\n",
    "        self.error = 0\n",
    "        self.output = 0\n",
    "        self.shape = (0,0)\n",
    "        \n",
    "    def stim(self, stim_results_hidden): # stimulate the perceptron - run the values through the sensor\n",
    "        # don't run the output layer through an activation function..  ******  I think I need the activation\n",
    "#         self.output = self.sigmoid(np.dot(X,self.weight))\n",
    "        self.output = self.sigmoid(np.dot(stim_results_hidden,self.weight))\n",
    "        return(self.output)\n",
    "        \n",
    "    def sigmoid(self, weighted_sum):\n",
    "        return 1 / (1 + np.exp(-weighted_sum))\n",
    "    \n",
    "    def sigmoid_(self, weighted_sum):\n",
    "        return(weighted_sum * (1 - weighted_sum))\n",
    "    \n",
    "    def get_error(self, y): \n",
    "        self.error = (y - self.output)\n",
    "        return(self.error)\n",
    "\n",
    "    def get_adjustment(self, stim_results_hidden): # updated to use stim_results_hidden vs x\n",
    "        delta = np.dot(stim_results_hidden.T, self.error * self.sigmoid_(self.output))  \n",
    "        return(delta)\n",
    "               \n",
    "    def update_weight(self, delta):\n",
    "        self.weight += delta\n",
    "        return(self.weight)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptron_H = pHidden((3,5))\n",
    "#print(\"Initial Weights hidden\")\n",
    "#print(ptron_H.weight)\n",
    "\n",
    "ptron_O = pOutput((5,1))\n",
    "#print(\"Initial Weights Output\")\n",
    "#print(ptron_O.weight)\n",
    "\n",
    "# reorder these to account for 2 layers\n",
    "for run in range(20000):\n",
    "    stim_results_hidden = ptron_H.stim(X)\n",
    "    #print(\"Stim Results Hidden\")\n",
    "    #print(stim_results_hidden)\n",
    "\n",
    "    stim_results_output = ptron_O.stim(stim_results_hidden)\n",
    "    #print(\"Stim Results Output\")\n",
    "    #print(stim_results_output)\n",
    "\n",
    "    error_output = ptron_O.get_error(y)\n",
    "    #print(\"calculated Error y - stim_results_output\")\n",
    "    #print(error_output)\n",
    "\n",
    "    delta_output = ptron_O.get_adjustment(stim_results_hidden)\n",
    "    #print(\"Delta Output\")\n",
    "    #print(delta_output)\n",
    "\n",
    "\n",
    "    update_output = ptron_O.update_weight(delta_output)\n",
    "    #print(\"update Output\")\n",
    "    #print(update_output)\n",
    "\n",
    "    delta_hidden = ptron_H.get_adjustment(error_output)\n",
    "    #print(\"Delta Hidden\")\n",
    "    #print(delta_hidden)\n",
    "\n",
    "    update_hidden = ptron_H.update_weight(delta_hidden)\n",
    "    #print(\"update hidden\")\n",
    "    #print(update_hidden)\n",
    "\n",
    "#     error_hidden = ptron_H.get_error(y)\n",
    "# #     #print(\"calculated Error\")\n",
    "# #     #print(error)\n",
    "\n",
    "#print(\"Final Weights hidden\")\n",
    "#print(ptron_H.weight)\n",
    "\n",
    "#print(\"Final weights output\")\n",
    "#print(ptron_O.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1] [ 0.50066201]\n",
      "[1 1 1] [ 0.01069735]\n",
      "[1 0 1] [ 0.99091409]\n",
      "[0 1 1] [ 0.99244118]\n"
     ]
    }
   ],
   "source": [
    "# run the observations through the model\n",
    "xor = np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "for obs in xor:\n",
    "    hidden_layer_test = ptron_H.stim(obs)\n",
    "    model_prediction = ptron_O.stim(hidden_layer_test)\n",
    "    print(obs,model_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#results @ 10,000 training iterations\n",
    "[0 0 1] [ 0.50123105]\n",
    "[1 1 1] [ 0.0151908]\n",
    "[1 0 1] [ 0.98708287]\n",
    "[0 1 1] [ 0.98921795]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
