{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from random import choice \n",
    "from numpy import array, dot, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Borrows heavily from saj raval code\n",
    "\n",
    "class Ptron(object):\n",
    "    def __init__(self):\n",
    "        # use the same seed every time for repeatability\n",
    "        random.seed(1988)\n",
    "        \n",
    "        # Assign random weights to matrix dimensions - len inputs X 1 - s/b 3 x 1 for our purposes\n",
    "        self.weights = random.rand(len(inputs),1) # initial weights\n",
    "        \n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "    \n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    # We train the neural network through a process of trial and error.\n",
    "    # Adjusting the synaptic weights each time.\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in xrange(number_of_training_iterations):\n",
    "            # Pass the training set through our neural network (a single neuron).\n",
    "            output = self.think(training_set_inputs)\n",
    "\n",
    "            # Calculate the error (The difference between the desired output\n",
    "            # and the predicted output).\n",
    "            error = training_set_outputs - output\n",
    "\n",
    "            # Multiply the error by the input and again by the gradient of the Sigmoid curve.\n",
    "            # This means less confident weights are adjusted more.\n",
    "            # This means inputs, which are zero, do not cause changes to the weights.\n",
    "            adjustment = dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
    "\n",
    "            # Adjust the weights.\n",
    "            self.synaptic_weights += adjustment\n",
    " \n",
    "    # The neural network thinks.\n",
    "    def think(self, inputs):\n",
    "        # Pass inputs through our neural network (our single neuron).\n",
    "        return self.__sigmoid(dot(inputs, self.synaptic_weights))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [ (array([0,0,1]), 0),\\\n",
    "                 (array([0,1,1]), 1), \\\n",
    "                 (array([1,0,1]), 1), \\\n",
    "                 (array([1,1,1]), 0), ] # changed expected to 0 for xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "eta = 0.2 \n",
    "n = 1000\n",
    "unit_step = lambda x: 0 if x < 0 else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XOR truth table\n",
    "# Input\tOutput\n",
    "# A\tB\n",
    "# 0\t0\t0\n",
    "# 0\t1\t1\n",
    "# 1\t0\t1\n",
    "# 1\t1\t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = random.rand(3)\n",
    "\n",
    "for i in range(n): \n",
    "    x, expected = choice(training_data) \n",
    "    \n",
    "    result = dot(w, x) \n",
    "    \n",
    "    error = expected - unit_step(result)\n",
    "\n",
    "    errors.append(error) \n",
    "    w += eta * error * x # if any of these are 0 then no change to array\n",
    "    # eta and x are never 0 so w changes proportional to error\n",
    "    \n",
    "#     print(\"eta {} - error {} - x {}\".format(eta,error,x))\n",
    "# #     print(x)\n",
    "# #     print(w)\n",
    "# #     print(result)\n",
    "# #     print(\"error is {}\".format(error))\n",
    "#     print(\"new weight is {}\".format(w))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]: 0.15152640721881527 -> 1\n",
      "[0 1]: 0.3915991145465545 -> 1\n",
      "[1 0]: 0.06997958882454619 -> 1\n",
      "[1 1]: 0.3100522961522854 -> 1\n"
     ]
    }
   ],
   "source": [
    "input_layer_result = []\n",
    "for x, _ in training_data: \n",
    "#     result = dot(x, w) # original code has w and x transposed.  No commutative property \n",
    "    result = dot(w,x)\n",
    "    print(\"{}: {} -> {}\".format(x[:2], result, unit_step(result)))\n",
    "    input_layer_result.append(unit_step(result))  # this becomes input to hidden layer 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a second layer -  this is hidden layer 1 h1\n",
    "# x can't change - start over with weights from input layer\n",
    "\n",
    "# start over with unit step results as the input *****\n",
    "\n",
    "# start with weights from previous layer  **** wrong - reinitialize the array with randoms\n",
    "\n",
    "h1_data = np.array(input_layer_result)\n",
    "h1_bias = np.ones(5)\n",
    "# h1_complete = np.append(h1_data,h1_bias,axis = 1)\n",
    "h1_complete = np.hstack((h1_data, h1_bias))\n",
    "\n",
    "# np.hstack((a,b))\n",
    "\n",
    "# for i in range(n): \n",
    "#     x, expected = choice(h1_complete) \n",
    "    \n",
    "#     result = dot(w, x) \n",
    "    \n",
    "#     error = expected - unit_step(result)\n",
    "\n",
    "#     errors.append(error) \n",
    "#     w += eta * error * x # if any of these are 0 then no change to array\n",
    "#     # eta and x are never 0 so w changes proportional to error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_complete.shape  # looking for a 2x5 array getting 0x9 - appending not adding second column\n",
    "### ************************  STOP HERE  ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]: 0.020992275188509157 -> 1\n",
      "[0 1]: 0.06705412087732765 -> 1\n",
      "[1 0]: -0.2427546470445786 -> 0\n",
      "[1 1]: -0.19669280135576012 -> 0\n"
     ]
    }
   ],
   "source": [
    "for x, _ in training_data: \n",
    "    result = dot(x, w) \n",
    "    print(\"{}: {} -> {}\".format(x[:2], result, unit_step(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
