{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parms for network\n",
    "hl_size = 1\n",
    "ol_size = 1\n",
    "\n",
    "# Number of training runs\n",
    "epoch = 100\n",
    "\n",
    "# Learning rate\n",
    "lr = .1\n",
    "\n",
    "# Data - also - Input layer\n",
    "training_X= np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "training_Y = np.array([[0],[1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding a perceptron\n",
    "\n",
    "class Perceptron(object):\n",
    "    \n",
    "    \"\"\"This class implements a simple perceptron allowing for multiple hidden \n",
    "    layers to be constructed.\"\"\"\n",
    "\n",
    "    def  __init__(self, training_X):\n",
    "                \n",
    "        # generate random synaptic weights for input layer\n",
    "        #hw - hidden weights - synaptic weight input for hidden layer\n",
    "        # ow - output weights - synaptic weight for output layer.\n",
    "        self.hw = np.random.rand(len(training_X[0]),ol_size)\n",
    "        self.ow = np.random.rand(ol_size,1) # need the 1 here to match\n",
    "#         self.\n",
    "      \n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    # this originally had a __ lead in which makes it private to the class.  May be better but I'm \n",
    "    # changing for now.\n",
    "    # wsi = weighted sum inputs\n",
    "    \n",
    "    def sigmoid(self, wsi):\n",
    "        return 1 / (1 + np.exp(-wsi))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    \n",
    "    def sigmoid_derivative(self, wsi):\n",
    "        return wsi * (1 - wsi)\n",
    "    \n",
    "    def hidden_layer(self, training_X):\n",
    "        dot_product = training_X * self.swi\n",
    "        return(dot_product)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptron = Perceptron(training_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlr \n",
      "[[ 0.54971131]\n",
      " [ 0.77071377]\n",
      " [ 0.66554625]\n",
      " [ 0.67343022]]\n",
      "olr \n",
      " [[ 0.53236979]\n",
      " [ 0.54532235]\n",
      " [ 0.53916523]\n",
      " [ 0.53962724]]\n",
      "Error training Y less output  \n",
      " [[-0.53236979]\n",
      " [ 0.45467765]\n",
      " [ 0.46083477]\n",
      " [-0.53962724]]\n",
      "Change in Z \n",
      "[[-0.81578737]\n",
      " [ 0.24794588]\n",
      " [ 0.24846609]\n",
      " [-0.83082479]]\n",
      "delta hidden is \n",
      " [[-0.10750189 -0.11011741 -0.1088741  -0.10896739]\n",
      " [ 0.02332606  0.02389358  0.02362381  0.02364405]\n",
      " [ 0.02944387  0.03016024  0.0298197   0.02984525]\n",
      " [-0.09727281 -0.09963945 -0.09851445 -0.09859886]]\n",
      "ptron.hlr [[-0.08702748 -0.08914486 -0.08813834 -0.08821387]]\n",
      "ptron.olr [[-0.61346153]]\n",
      "hlr \n",
      "[[ 0.54971131]\n",
      " [ 0.77071377]\n",
      " [ 0.66554625]\n",
      " [ 0.67343022]]\n",
      "olr \n",
      " [[ 0.53236979]\n",
      " [ 0.54532235]\n",
      " [ 0.53916523]\n",
      " [ 0.53962724]]\n",
      "Error training Y less output  \n",
      " [[-0.53236979]\n",
      " [ 0.45467765]\n",
      " [ 0.46083477]\n",
      " [-0.53962724]]\n",
      "Change in Z \n",
      "[[-0.81578737]\n",
      " [ 0.24794588]\n",
      " [ 0.24846609]\n",
      " [-0.83082479]]\n",
      "delta hidden is \n",
      " [[-0.10750189 -0.11011741 -0.1088741  -0.10896739]\n",
      " [ 0.02332606  0.02389358  0.02362381  0.02364405]\n",
      " [ 0.02944387  0.03016024  0.0298197   0.02984525]\n",
      " [-0.09727281 -0.09963945 -0.09851445 -0.09859886]]\n",
      "ptron.hlr [[-0.08702748 -0.08914486 -0.08813834 -0.08821387]]\n",
      "ptron.olr [[-0.61346153]]\n",
      "hlr \n",
      "[[ 0.54971131]\n",
      " [ 0.77071377]\n",
      " [ 0.66554625]\n",
      " [ 0.67343022]]\n",
      "olr \n",
      " [[ 0.53236979]\n",
      " [ 0.54532235]\n",
      " [ 0.53916523]\n",
      " [ 0.53962724]]\n",
      "Error training Y less output  \n",
      " [[-0.53236979]\n",
      " [ 0.45467765]\n",
      " [ 0.46083477]\n",
      " [-0.53962724]]\n",
      "Change in Z \n",
      "[[-0.81578737]\n",
      " [ 0.24794588]\n",
      " [ 0.24846609]\n",
      " [-0.83082479]]\n",
      "delta hidden is \n",
      " [[-0.10750189 -0.11011741 -0.1088741  -0.10896739]\n",
      " [ 0.02332606  0.02389358  0.02362381  0.02364405]\n",
      " [ 0.02944387  0.03016024  0.0298197   0.02984525]\n",
      " [-0.09727281 -0.09963945 -0.09851445 -0.09859886]]\n",
      "ptron.hlr [[-0.08702748 -0.08914486 -0.08813834 -0.08821387]]\n",
      "ptron.olr [[-0.61346153]]\n",
      "final output matrix \n",
      " [[-0.61346153]]\n"
     ]
    }
   ],
   "source": [
    "for x in range(3):\n",
    "\n",
    "    # get the hiden layer result\n",
    "    # i values in pic represent rows\n",
    "    hlr = ptron.sigmoid(np.dot(training_X, ptron.hw))\n",
    "\n",
    "    print(\"hlr \\n{}\".format(hlr))\n",
    "\n",
    "    # get the output layer result = sigmoid * hlr * output weights\n",
    "    olr = ptron.sigmoid(np.dot(hlr, ptron.ow))\n",
    "    print(\"olr \\n {}\".format(olr))\n",
    "\n",
    "    # calculate the error\n",
    "    Z = training_Y - olr\n",
    "    print(\"Error training Y less output  \\n {}\".format(Z))\n",
    "\n",
    "    # Calculate the change in output layer Z\n",
    "    dZ = ptron.sigmoid_derivative(Z)\n",
    "    print(\"Change in Z \\n{}\".format(dZ))\n",
    "\n",
    "    # calculate how much to change hidden layer weight\n",
    "\n",
    "    # dH = dZ.dot(Wz.T) * sigmoid_(H\n",
    "\n",
    "    dH = np.dot(dZ,olr.T) * ptron.sigmoid_derivative(hlr)\n",
    "    print(\"delta hidden is \\n {}\".format(dH))\n",
    "\n",
    "    # update the weights\n",
    "\n",
    "    ptron.hlr = hlr.T.dot(dH)  # hidden layer result. transpose dot multiply by delta output layer\n",
    "    print(\"ptron.hlr {}\".format(ptron.hlr))\n",
    "\n",
    "\n",
    "    ptron.olr = olr.T.dot(dZ) # output layer result\n",
    "    print(\"ptron.olr {}\".format(ptron.olr))\n",
    "\n",
    "print(\"final output matrix \\n {}\".format(ptron.olr))\n",
    "\n",
    "#  Wz +=  H.T.dot(dZ) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15412639,  0.35861796,  0.34916662,  0.16357773]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15412639],\n",
       "       [ 0.35861796],\n",
       "       [ 0.34916662],\n",
       "       [ 0.16357773]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1), (4, 1))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, olr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27216161],\n",
       "       [ 0.85881347],\n",
       "       [ 0.76346348]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9900"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.sigmoid_derivative(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.76356988],\n",
       "       [ 0.02011772,  0.02011772,  0.02011772],\n",
       "       [ 0.87281578,  0.        ,  0.87281578],\n",
       "       [ 0.        ,  0.32069146,  0.32069146]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.hidden_layer(training_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
