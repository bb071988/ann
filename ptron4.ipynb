{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parms for network\n",
    "hl_size = 1\n",
    "ol_size = 1\n",
    "\n",
    "# Number of training runs\n",
    "epoch = 100\n",
    "\n",
    "# Learning rate\n",
    "lr = .1\n",
    "\n",
    "# Data - also - Input layer\n",
    "training_X= np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "training_Y = np.array([[0],[1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding a perceptron\n",
    "\n",
    "class Perceptron(object):\n",
    "    \n",
    "    \"\"\"This class implements a simple perceptron allowing for multiple hidden \n",
    "    layers to be constructed.\"\"\"\n",
    "\n",
    "    def  __init__(self, training_X):\n",
    "                \n",
    "        # generate random synaptic weights for input layer\n",
    "        #hw - hidden weights - synaptic weight input for hidden layer\n",
    "        # ow - output weights - synaptic weight for output layer.\n",
    "        self.hw = np.random.rand(len(training_X[0]),ol_size)\n",
    "        self.ow = np.random.rand(ol_size,1) # need the 1 here to match\n",
    "#         self.\n",
    "      \n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    # this originally had a __ lead in which makes it private to the class.  May be better but I'm \n",
    "    # changing for now.\n",
    "    # wsi = weighted sum inputs\n",
    "    \n",
    "    def sigmoid(self, wsi):\n",
    "        return 1 / (1 + np.exp(-wsi))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    \n",
    "    def sigmoid_derivative(self, wsi):\n",
    "        return wsi * (1 - wsi)\n",
    "    \n",
    "    def hidden_layer(self, training_X):\n",
    "        dot_product = training_X * self.swi\n",
    "        return(dot_product)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptron = Perceptron(training_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlr \n",
      "[[ 0.53196093]\n",
      " [ 0.81183146]\n",
      " [ 0.6896838 ]\n",
      " [ 0.68811716]]\n",
      "olr \n",
      " [[ 0.54108146]\n",
      " [ 0.56250779]\n",
      " [ 0.55318027]\n",
      " [ 0.55306038]]\n",
      "Error training Y less output  \n",
      " [[-0.54108146]\n",
      " [ 0.43749221]\n",
      " [ 0.44681973]\n",
      " [-0.55306038]]\n",
      "Change in Z \n",
      "[[-0.83385061]\n",
      " [ 0.24609278]\n",
      " [ 0.24717186]\n",
      " [-0.85893617]]\n",
      "delta hidden is \n",
      " [[-0.11233439 -0.11678273 -0.11484624 -0.11482135]\n",
      " [ 0.0203411   0.02114659  0.02079593  0.02079143]\n",
      " [ 0.02862307  0.02975651  0.02926309  0.02925675]\n",
      " [-0.09974185 -0.10369153 -0.10197212 -0.10195002]]\n",
      "ptron.hlr [[-0.09213718 -0.09578573 -0.0941974  -0.09417699]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (4,1) and (4,1) not aligned: 1 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-dd33db83c071>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0molr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0molr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output layer result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ptron.olr {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0molr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,1) and (4,1) not aligned: 1 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "for x in range(1):\n",
    "\n",
    "    # get the hiden layer result\n",
    "    # i values in pic represent rows\n",
    "    hlr = ptron.sigmoid(np.dot(training_X, ptron.hw))\n",
    "    \n",
    "\n",
    "    print(\"hlr \\n{}\".format(hlr))\n",
    "\n",
    "    # get the output layer result = sigmoid * hlr * output weights\n",
    "    # hiden layer through activation before output weights.\n",
    "    #\n",
    "    \n",
    "    olr = ptron.sigmoid(np.dot(hlr, ptron.ow))\n",
    "    print(\"olr \\n {}\".format(olr))\n",
    "\n",
    "    # calculate the error\n",
    "    Z = training_Y - olr\n",
    "    print(\"Error training Y less output  \\n {}\".format(Z))\n",
    "\n",
    "    # Calculate the change in output layer Z\n",
    "    dZ = ptron.sigmoid_derivative(Z)\n",
    "    print(\"Change in Z \\n{}\".format(dZ))\n",
    "\n",
    "    # calculate how much to change hidden layer weight\n",
    "\n",
    "    # dH = dZ.dot(Wz.T) * sigmoid_(H\n",
    "\n",
    "    dH = np.dot(dZ,olr.T) * ptron.sigmoid_derivative(hlr)\n",
    "    print(\"delta hidden is \\n {}\".format(dH))\n",
    "\n",
    "    # update the weights\n",
    "\n",
    "    ptron.hlr = hlr.T.dot(dH)  # hidden layer result. transpose dot multiply by delta output layer\n",
    "    print(\"ptron.hlr {}\".format(ptron.hlr))\n",
    "\n",
    "\n",
    "    ptron.olr = olr.dot(dZ) # output layer result\n",
    "    print(\"ptron.olr {}\".format(ptron.olr))\n",
    "\n",
    "print(\"final output matrix \\n {}\".format(ptron.olr))\n",
    "\n",
    "#  Wz +=  H.T.dot(dZ) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15412639,  0.35861796,  0.34916662,  0.16357773]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15412639],\n",
       "       [ 0.35861796],\n",
       "       [ 0.34916662],\n",
       "       [ 0.16357773]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1), (4, 1))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, olr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27216161],\n",
       "       [ 0.85881347],\n",
       "       [ 0.76346348]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9900"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.sigmoid_derivative(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.76356988],\n",
       "       [ 0.02011772,  0.02011772,  0.02011772],\n",
       "       [ 0.87281578,  0.        ,  0.87281578],\n",
       "       [ 0.        ,  0.32069146,  0.32069146]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.hidden_layer(training_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
